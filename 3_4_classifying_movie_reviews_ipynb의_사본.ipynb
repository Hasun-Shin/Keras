{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "3.4-classifying-movie-reviews.ipynb의 사본",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasun-Shin/Keras/blob/master/3_4_classifying_movie_reviews_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVfAsmePbnse",
        "colab_type": "code",
        "outputId": "5a119c22-6c46-47a4-9eaf-97c2e54e1dd1",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbP7-vPsbnsn",
        "colab_type": "text"
      },
      "source": [
        "# 영화 리뷰 분류: 이진 분류 예제\n",
        "\n",
        "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/%EC%BC%80%EB%9D%BC%EC%8A%A4-%EB%94%A5%EB%9F%AC%EB%8B%9D/) 책의 3장 4절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다.\n",
        "\n",
        "----\n",
        "\n",
        "2종 분류 또는 이진 분류는 아마도 가장 널리 적용된 머신 러닝 문제일 것입니다. 이 예제에서 리뷰 텍스트를 기반으로 영화 리뷰를 긍정과 부정로 분류하는 법을 배우겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALeaNWzXbnsp",
        "colab_type": "text"
      },
      "source": [
        "## IMDB 데이터셋\n",
        "\n",
        "인터넷 영화 데이터베이스로부터 가져온 양극단의 리뷰 50,000개로 이루어진 IMDB 데이터셋을 사용하겠습니다. 이 데이터셋은 훈련 데이터 25,000개와 테스트 데이터 25,000개로 나뉘어 있고 각각 50%는 부정, 50%는 긍정 리뷰로 구성되어 있습니다.\n",
        "\n",
        "왜 훈련 데이터와 테스트 데이터를 나눌까요? 같은 데이터에서 머신 러닝 모델을 훈련하고 테스트해서는 절대 안 되기 때문입니다! 모델이 훈련 데이터에서 잘 작동한다는 것이 처음 만난 데이터에서도 잘 동작한다는 것을 보장하지 않습니다. 중요한 것은 새로운 데이터에 대한 모델의 성능입니다(사실 훈련 데이터의 레이블은 이미 알고 있기 때문에 이를 예측하는 모델은 필요하지 않습니다). 예를 들어 모델이 훈련 샘플과 타깃 사이의 매핑을 모두 외워버릴 수 있습니다. 이런 모델은 처음 만나는 데이터에서 타깃을 예측하는 작업에는 쓸모가 없습니다. 다음 장에서 이에 대해 더 자세히 살펴보겠습니다.\n",
        "\n",
        "MNIST 데이터셋처럼 IMDB 데이터셋도 케라스에 포함되어 있습니다. 이 데이터는 전처리되어 있어 각 리뷰(단어 시퀀스)가 숫자 시퀀스로 변환되어 있습니다. 여기서 각 숫자는 사전에 있는 고유한 단어를 나타냅니다.\n",
        "\n",
        "다음 코드는 데이터셋을 로드합니다(처음 실행하면 17MB 정도의 데이터가 컴퓨터에 다운로드됩니다):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJGoBrQDbnsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "980ab6ad-e9a0-43e0-c99c-d25e6cb09351"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcxO-eaMl0VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzsUj3Gabnsy",
        "colab_type": "text"
      },
      "source": [
        "매개변수 `num_words=10000`은 훈련 데이터에서 가장 자주 나타나는 단어 10,000개만 사용하겠다는 의미입니다. 드물게 나타나는 단어는 무시하겠습니다. 이렇게 하면 적절한 크기의 벡터 데이터를 얻을 수 있습니다.\n",
        "\n",
        "변수 `train_data`와 `test_data`는 리뷰의 목록입니다. 각 리뷰는 단어 인덱스의 리스트입니다(단어 시퀀스가 인코딩된 것입니다). `train_labels`와 `test_labels`는 부정을 나타내는 0과 긍정을 나타내는 1의 리스트입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhk1J0jWbns0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkhDs0hXbns5",
        "colab_type": "code",
        "outputId": "239963d8-a15f-41a2-9ee9-4dfcd03ca6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(train_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 ... 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0AVPoefbns_",
        "colab_type": "text"
      },
      "source": [
        "가장 자주 등장하는 단어 10,000개로 제한했기 때문에 단어 인덱스는 10,000을 넘지 않습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT9KiAP6bntA",
        "colab_type": "code",
        "outputId": "487ea4d0-ea3e-4334-e167-e30374d3cdf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMnlGOSbbntH",
        "colab_type": "text"
      },
      "source": [
        "재미 삼아 이 리뷰 데이터 하나를 원래 영어 단어로 어떻게 바꾸는지 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDJIzVf2bntJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# word_index는 단어와 정수 인덱스를 매핑한 딕셔너리입니다\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "print(word_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y7XptE_dZ3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 정수 인덱스와 단어를 매핑하도록 뒤집습니다\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# reverse_word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuB0rMdEdvA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 리뷰를 디코딩합니다. \n",
        "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf01RLw-bntM",
        "colab_type": "code",
        "outputId": "61d84b4c-89d0-4256-e112-0b2322791b1c",
        "colab": {}
      },
      "source": [
        "decoded_review"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvk3x4RrbntS",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 준비\n",
        "\n",
        "신경망에 숫자 리스트를 주입할 수는 없습니다. 리스트를 텐서로 바꾸는 두 가지 방법이 있습니다:\n",
        "\n",
        "* 같은 길이가 되도록 리스트에 패딩을 추가하고 `(samples, sequence_length)` 크기의 정수 텐서로 변환합니다. 그다음 이 정수 텐서를 다룰 수 있는 층을 신경망의 첫 번째 층으로 사용합니다(`Embedding` 층을 말하며 나중에 자세히 다루겠습니다).\n",
        "* 리스트를 원-핫 인코딩하여 0과 1의 벡터로 변환합니다. 예를 들면 시퀀스 `[3, 5]`를 인덱스 3과 5의 위치는 1이고 그 외는 모두 0인 10,000차원의 벡터로 각각 변환합니다. 그다음 부동 소수 벡터 데이터를 다룰 수 있는 `Dense` 층을 신경망의 첫 번째 층으로 사용합니다.\n",
        "\n",
        "여기서는 두 번째 방식을 사용하고 이해를 돕기 위해 직접 데이터를 원-핫 벡터로 만들겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oEUIot0bntU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    # 크기가 (len(sequences), dimension))이고 모든 원소가 0인 행렬을 만듭니다\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.  # results[i]에서 특정 인덱스의 위치를 1로 만듭니다\n",
        "    return results\n",
        "\n",
        "# 훈련 데이터를 벡터로 변환합니다\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 테스트 데이터를 벡터로 변환합니다\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwDcupjrbntb",
        "colab_type": "text"
      },
      "source": [
        "이제 샘플은 다음과 같이 나타납니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAhSpyXnbntc",
        "colab_type": "code",
        "outputId": "2f3d2fa6-8369-43d2-9713-7fc19c964867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train[0]\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkVdmfqDbnth",
        "colab_type": "text"
      },
      "source": [
        "레이블은 쉽게 벡터로 바꿀 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpTX0-2ibnti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 레이블을 벡터로 바꿉니다\n",
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5I8gQa-bnto",
        "colab_type": "text"
      },
      "source": [
        "이제 신경망에 주입할 데이터가 준비되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwzHY6Fbbntq",
        "colab_type": "text"
      },
      "source": [
        "## 신경망 모델 만들기\n",
        "\n",
        "입력 데이터가 벡터이고 레이블은 스칼라(1 또는 0)입니다. 아마 앞으로 볼 수 있는 문제 중에서 가장 간단할 것입니다. 이런 문제에 잘 작동하는 네트워크 종류는 `relu` 활성화 함수를 사용한 완전 연결 층(즉, `Dense(16, activation='relu')`)을 그냥 쌓은 것입니다.\n",
        "\n",
        "`Dense` 층에 전달한 매개변수(16)는 은닉 유닛의 개수입니다. 하나의 은닉 유닛은 층이 나타내는 표현 공간에서 하나의 차원이 됩니다. 2장에서 `relu` 활성화 함수를 사용한 `Dense` 층을 다음과 같은 텐서 연산을 연결하여 구현하였습니다:\n",
        "\n",
        "`output = relu(dot(W, input) + b)`\n",
        "\n",
        "16개의 은닉 유닛이 있다는 것은 가중치 행렬 `W`의 크기가 `(input_dimension, 16)`이라는 뜻입니다. 입력 데이터와 `W`를 점곱하면 입력 데이터가 16 차원으로 표현된 공간으로 투영됩니다(그리고 편향 벡터 `b`를 더하고 `relu` 연산을 적용합니다). 표현 공간의 차원을 '신경망이 내재된 표현을 학습할 때 가질 수 있는 자유도'로 이해할 수 있습니다. 은닉 유닛을 늘리면 (표현 공간을 더 고차원으로 만들면) 신경망이 더욱 복잡한 표현을 학습할 수 있지만 계산 비용이 커지고 원치 않은 패턴을 학습할 수도 있습니다(훈련 데이터에서는 성능이 향상되지만 테스트 데이터에서는 그렇지 않은 패턴입니다).\n",
        "\n",
        "`Dense` 층을 쌓을 때 두 가진 중요한 구조상의 결정이 필요합니다:\n",
        "\n",
        "* 얼마나 많은 층을 사용할 것인가\n",
        "* 각 층에 얼마나 많은 은닉 유닛을 둘 것인가\n",
        "\n",
        "4장에서 이런 결정을 하는 데 도움이 되는 일반적인 원리를 배우겠습니다. 당분간은 저를 믿고 선택한 다음 구조를 따라 주세요.\n",
        "\n",
        "* 16개의 은닉 유닛을 가진 두 개의 은닉층\n",
        "* 현재 리뷰의 감정을 스칼라 값의 예측으로 출력하는 세 번째 층\n",
        "\n",
        "중간에 있는 은닉층은 활성화 함수로 `relu`를 사용하고 마지막 층은 확률(0과 1 사이의 점수로, 어떤 샘플이 타깃 '1'일 가능성이 높다는 것은 그 리뷰가 긍정일 가능성이 높다는 것을 의미합니다)을 출력하기 위해 시그모이드 활성화 함수를 사용합니다. `relu`는 음수를 0으로 만드는 함수입니다. 시그모이드는 임의의 값을 [0, 1] 사이로 압축하므로 출력 값을 확률처럼 해석할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5-_-ZR3bnts",
        "colab_type": "text"
      },
      "source": [
        "다음이 이 신경망의 모습입니다:\n",
        "\n",
        "![3-layer network](https://s3.amazonaws.com/book.keras.io/img/ch3/3_layer_network.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBlCdaEMbntv",
        "colab_type": "text"
      },
      "source": [
        "다음은 이 신경망의 케라스 구현입니다. 이전에 보았던 MNIST 예제와 비슷합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9fRZkN4bntw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#한층이면 softmax 나 sigmoid ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjvLjDcsbnt3",
        "colab_type": "text"
      },
      "source": [
        "마지막으로 손실 함수와 옵티마이저를 선택해야 합니다. 이진 분류 문제이고 신경망의 출력이 확률이기 때문에(네트워크의 끝에 시그모이드 활성화 함수를 사용한 하나의 유닛으로 된 층을 놓았습니다), `binary_crossentropy` 손실이 적합합니다. 이 함수가 유일한 선택은 아니고 예를 들어 `mean_squared_error`를 사용할 수도 있습니다. 확률을 출력하는 모델을 사용할 때는 크로스엔트로피가 최선의 선택입니다. 크로스엔트로피는 정보 이론 분야에서 온 개념으로 확률 분포 간의 차이를 측정합니다. 여기에서는 원본 분포와 예측 분포 사이를 측정합니다.\n",
        "\n",
        "다음은 `rmsprop` 옵티마이저와 `binary_crossentropy` 손실 함수로 모델을 설정하는 단계입니다. 훈련하는 동안 정확도를 사용해 모니터링하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltp-EgjQbnt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#로스함수 종류들 ; https://keras.io/losses/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIhsrHOVbnt8",
        "colab_type": "text"
      },
      "source": [
        "케라스에 `rmsprop`, `binary_crossentropy`, `accuracy`가 포함되어 있기 때문에 옵티마이저, 손실 함수, 측정 지표를 문자열로 지정하는 것이 가능합니다. 이따금 옵티마이저의 매개변수를 바꾸거나 자신만의 손실 함수, 측정 함수를 전달해야 할 경우가 있습니다. 전자의 경우에는 옵티마이저 파이썬 클래스를 사용해 객체를 직접 만들어 `optimizer` 매개변수에 전달하면 됩니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ghx5jO0bnt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI2YR_LwbnuB",
        "colab_type": "text"
      },
      "source": [
        "후자의 경우는 `loss`와 `metrics` 매개변수에 함수 객체를 전달하면 됩니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2X2ZjjjbnuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import losses\n",
        "from keras import metrics\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=[metrics.binary_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaqJ3TgCbnuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91p7_fjybnuI",
        "colab_type": "text"
      },
      "source": [
        "## 훈련 검증\n",
        "\n",
        "훈련하는 동안 처음 본 데이터에 대한 모델의 정확도를 측정하기 위해서는 원본 훈련 데이터에서 10,000의 샘플을 떼어서 검증 세트를 만들어야 합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvL836-LbnuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pCeFentHbnuP",
        "colab_type": "text"
      },
      "source": [
        "이제 모델을 512개 샘플씩 미니 배치를 만들어 20번의 에포크 동안 훈련시킵니다(`x_train`과 `y_train` 텐서에 있는 모든 샘플에 대해 20번 반복합니다). 동시에 따로 떼어 놓은 10,000개의 샘플에서 손실과 정확도를 측정할 것입니다. 이렇게 하려면 `validation_data` 매개변수에 검증 데이터를 전달해야 합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmZ5aN73bnuQ",
        "colab_type": "code",
        "outputId": "8b9176d0-7398-4869-8d4b-7198d0dc4ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "15000/15000 [==============================] - 2s 136us/step - loss: 0.4986 - acc: 0.7899 - val_loss: 0.3671 - val_acc: 0.8744\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.2937 - acc: 0.9055 - val_loss: 0.2972 - val_acc: 0.8916\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.2180 - acc: 0.9287 - val_loss: 0.2825 - val_acc: 0.8892\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.1706 - acc: 0.9456 - val_loss: 0.2903 - val_acc: 0.8833\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 88us/step - loss: 0.1412 - acc: 0.9551 - val_loss: 0.2877 - val_acc: 0.8863\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.1134 - acc: 0.9652 - val_loss: 0.3264 - val_acc: 0.8792\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 91us/step - loss: 0.0955 - acc: 0.9717 - val_loss: 0.3179 - val_acc: 0.8803\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0794 - acc: 0.9775 - val_loss: 0.3379 - val_acc: 0.8773\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 91us/step - loss: 0.0642 - acc: 0.9835 - val_loss: 0.3935 - val_acc: 0.8694\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0557 - acc: 0.9853 - val_loss: 0.3829 - val_acc: 0.8765\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0406 - acc: 0.9907 - val_loss: 0.4114 - val_acc: 0.8742\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 91us/step - loss: 0.0361 - acc: 0.9925 - val_loss: 0.4452 - val_acc: 0.8713\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0280 - acc: 0.9952 - val_loss: 0.4733 - val_acc: 0.8713\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0235 - acc: 0.9957 - val_loss: 0.5068 - val_acc: 0.8703\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.0168 - acc: 0.9979 - val_loss: 0.5443 - val_acc: 0.8681\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0159 - acc: 0.9976 - val_loss: 0.5674 - val_acc: 0.8682\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0112 - acc: 0.9986 - val_loss: 0.6926 - val_acc: 0.8503\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 89us/step - loss: 0.0076 - acc: 0.9998 - val_loss: 0.6243 - val_acc: 0.8653\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 90us/step - loss: 0.0067 - acc: 0.9995 - val_loss: 0.6599 - val_acc: 0.8661\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 91us/step - loss: 0.0066 - acc: 0.9990 - val_loss: 0.6890 - val_acc: 0.8633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukQKV2yfbnuT",
        "colab_type": "text"
      },
      "source": [
        "CPU를 사용해도 에포크마다 2초가 걸리지 않습니다. 전체 훈련은 20초 이상 걸립니다. 에포크가 끝날 때마다 10,000개의 검증 샘플 데이터에서 손실과 정확도를 계산하기 때문에 약간씩 지연됩니다.\n",
        "\n",
        "`model.fit()` 메서드는 `History` 객체를 반환합니다. 이 객체는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리인 `history` 속성을 가지고 있습니다. 한 번 확인해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz3INTZObnuU",
        "colab_type": "code",
        "outputId": "91ace240-4ce0-4f40-940c-aa5f65f2a25f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tezvKL-IbnuX",
        "colab_type": "text"
      },
      "source": [
        "이 딕셔너리는 훈련과 검증하는 동안 모니터링할 측정 지표당 하나씩 모두 네 개의 항목을 담고 있습니다. 맷플롯립을 사용해 훈련과 검증 데이터에 대한 손실과 정확도를 그려 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruuxVVd9bnuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-dpuj1Jbnuf",
        "colab_type": "code",
        "outputId": "a56afb7d-de6e-49a1-85c2-958c4e3c1883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# ‘bo’는 파란색 점을 의미합니다\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# ‘b’는 파란색 실선을 의미합니다\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyXJKBCIiWU6JQEQky/1/3x+FlXnQuVYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7jyxdDJbnui",
        "colab_type": "code",
        "outputId": "daa5e2de-c39b-4165-b782-e329e0a7af0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.clf()   # 그래프를 초기화합니다\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deZgU1dn38e8NCMgiq7iwDSiKGmWb\nYMSgGJeAGhHFKKKCmiC4RRND9NEY1PA8MWo0RjRi3CWCviZEE4wLLjExKiOyK7I4IoiKKJuIMHC/\nf5xq6BlqZprpbZbf57rq6ura+u6iqXvOOXVOmbsjIiJSVr18ByAiItWTEoSIiMRSghARkVhKECIi\nEksJQkREYilBiIhILCUISZmZPWtmIzK9bT6ZWbGZHZeF47qZ7R/N/9HMfpnKtlX4nOFm9nxV4xSp\niKkfRO1mZhuS3jYBvgG2Ru8vcvdJuY+q+jCzYuBH7v5iho/rQDd3X5ypbc2sAPgA2M3dSzIRp0hF\nGuQ7AMkud2+WmK/oYmhmDXTRkepCv8fqQVVMdZSZDTCz5Wb2CzP7BHjQzFqZ2d/NbJWZfRnNd0ja\n5xUz+1E0P9LM/m1mt0bbfmBmg6q4bRcz+5eZrTezF81sgpk9Vk7cqcR4k5n9Jzre82bWNmn9uWb2\noZmtNrNrKzg/h5vZJ2ZWP2nZEDObE833NbP/mtkaM1tpZneZWcNyjvWQmf066f3Po30+NrMLymx7\nkpm9Y2brzOwjMxuXtPpf0esaM9tgZkckzm3S/v3MbIaZrY1e+6V6bnbxPLc2swej7/ClmU1NWjfY\nzGZF32GJmQ2MlpeqzjOzcYl/ZzMriKraLjSzZcBL0fIno3+HtdFv5JCk/Xc3s9uif8+10W9sdzP7\nh5ldVub7zDGzIXHfVcqnBFG37Q20BjoDowi/hwej952Ar4G7Ktj/cGAh0Bb4LXC/mVkVtv0z8BbQ\nBhgHnFvBZ6YS49nA+UA7oCFwFYCZHQzcEx1/3+jzOhDD3d8EvgK+V+a4f47mtwJXRt/nCOBY4OIK\n4iaKYWAUz/FAN6Bs+8dXwHlAS+AkYIyZnRqtOyp6benuzdz9v2WO3Rr4B3Bn9N1+B/zDzNqU+Q47\nnZsYlZ3nRwlVlodEx7o9iqEv8Ajw8+g7HAUUl3c+YhwNHAR8P3r/LOE8tQNmAslVorcCfYB+hN/x\nWGAb8DBwTmIjM+sBtCecG9kV7q6pjkyE/6jHRfMDgM1A4wq27wl8mfT+FUIVFcBIYHHSuiaAA3vv\nyraEi08J0CRp/WPAYyl+p7gYr0t6fzHwz2j+emBy0rqm0Tk4rpxj/xp4IJpvTrh4dy5n2yuAvya9\nd2D/aP4h4NfR/APAb5K2OyB525jj3gHcHs0XRNs2SFo/Evh3NH8u8FaZ/f8LjKzs3OzKeQb2IVyI\nW8Vsd28i3op+f9H7cYl/56Tv1rWCGFpG27QgJLCvgR4x2zUGviS060BIJHfn+v9bbZhUgqjbVrn7\npsQbM2tiZvdGRfZ1hCqNlsnVLGV8kphx943RbLNd3HZf4IukZQAflRdwijF+kjS/MSmmfZOP7e5f\nAavL+yxCaeE0M2sEnAbMdPcPozgOiKpdPoni+F9CaaIypWIAPizz/Q43s5ejqp21wOgUj5s49odl\nln1I+Os5obxzU0ol57kj4d/sy5hdOwJLUow3zvZzY2b1zew3UTXVOnaURNpGU+O4z4p+01OAc8ys\nHjCMUOKRXaQEUbeVvYXtZ8CBwOHuvgc7qjTKqzbKhJVAazNrkrSsYwXbpxPjyuRjR5/ZpryN3X0B\n4QI7iNLVSxCqqt4j/JW6B/A/VYmBUIJK9mfgaaCju7cA/ph03MpuOfyYUCWUrBOwIoW4yqroPH9E\n+DdrGbPfR8B+5RzzK0LpMWHvmG2Sv+PZwGBCNVwLQikjEcPnwKYKPuthYDih6m+jl6mOk9QoQUiy\n5oRi+5qoPvtX2f7A6C/yImCcmTU0syOAH2Qpxv8HnGxm340alG+k8v8DfwZ+QrhAPlkmjnXABjPr\nDoxJMYYngJFmdnCUoMrG35zw1/mmqD7/7KR1qwhVO13LOfY04AAzO9vMGpjZmcDBwN9TjK1sHLHn\n2d1XEtoG7o4as3czs0QCuR8438yONbN6ZtY+Oj8As4Czou0LgaEpxPANoZTXhFBKS8SwjVBd9zsz\n2zcqbRwRlfaIEsI24DZUeqgyJQhJdgewO+GvszeAf+boc4cTGnpXE+r9pxAuDHGqHKO7zwcuIVz0\nVxLqqZdXstvjhIbTl9z986TlVxEu3uuB+6KYU4nh2eg7vAQsjl6TXQzcaGbrCW0mTyTtuxEYD/zH\nwt1T3ylz7NXAyYS//lcTGm1PLhN3qio7z+cCWwilqM8IbTC4+1uERvDbgbXAq+wo1fyS8Bf/l8AN\nlC6RxXmEUIJbASyI4kh2FTAXmAF8AdxM6WvaI8ChhDYtqQJ1lJNqx8ymAO+5e9ZLMFJ7mdl5wCh3\n/26+Y6mpVIKQvDOzb5vZflGVxEBCvfPUyvYTKU9UfXcxMDHfsdRkShBSHexNuAVzA+Ee/jHu/k5e\nI5Iay8y+T2iv+ZTKq7GkAqpiEhGRWCpBiIhIrFozWF/btm29oKAg32GIiNQob7/99ufuvmfculqT\nIAoKCigqKsp3GCIiNYqZle19v52qmEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiZS1BmNkDZvaZ\nmc0rZ72Z2Z1mtjh6HGDvpHUjzGxRNI3IVowiIumYNAkKCqBevfA6aVJle2R2/2zLZgniIWBgBesH\nER4l2I3wuMt7YPtjE39FeERlX+BXZtYqi3GKSB2VzgV60iQYNQo+/BDcw+uoUakfI939040/Jdl8\nXB3hAR/zyll3LzAs6f1CwqMMhwH3lrddeVOfPn1cRGqWxx5z79zZ3Sy8PvZY7vZ/7DH3Jk3cw+U5\nTE2apH6Mzp1L75uYOnfOzf7pxp8AFHk1fORoe0o/enF5tKy85Tsxs1FmVmRmRatWrcpaoCKSefn+\nC/zaa2HjxtLLNm4My1OxbNmuLc/0/unGn4oa3Ujt7hPdvdDdC/fcM7anuIhkUTpVHOle4PJ9ge9U\n9mGxlSzP9P7pxp+KfCaIFZR+Nm+HaFl5y0Ukw/JZB5/vv8DTvUCPHw9NmpRe1qRJWJ6L/dONPyXl\n1T1lYqLiNoiTCM+1NeA7wFvR8tbAB0CraPoAaF3ZZ6kNQmTX1PQ6+OpQh1+T21ASqKANIpvJ4XHC\nc3+3ENoRLgRGA6Oj9QZMAJYQnitbmLTvBYTn9S4Gzk/l85QgpC5K5wKT7gXWLH5/s9RjT+cCVx0u\n8PmWifjzkiByPSlBSF2T7gUy3Qt8ugkm8R3y9Re4BBUliBrdSC1S0+WzkTffdfAAw4dDcTFs2xZe\nhw9Pfd9M7C8VU4IQyZN8N/Kme4EfPhwmToTOncEsvE6cqIt0bVJrnkldWFjoemCQ1CQFBSEplNW5\nc/hrONv7Q0hG114bkkqnTiE56AJft5jZ2+5eGLdOJQiRPMl3CQBURSMVU4IQyZN02wBUxSPZpgQh\nkoZ0GplVApDqTglCpIrSbWRWCUCqOyUIqdPyeZspqAQg1VuDfAcgki+JEkDiIp8oAUBqF+pcDJYm\nkk8qQUidle+OZiLVnRKE1FnV4TZTkepMCULqLN1mKlIxJQip0XSbqUj2KEFIjaXbTEWyS2MxSY2V\nibGIROo6jcUktZJuMxXJLiUIqbF0m6lIdilBSI2l20xFsksJQvIqnbuQ1Mgskl0aakPyJt2hLhLb\nKSGIZIdKEJI3mRjsTkSyRwlC8kZ3IYlUb0oQkje6C0mkelOCkLzRXUgi1ZsShKRFdyGJ1F66i0mq\nTHchidRuKkFIlekuJJHaTQlCqkx3IYnUbkoQUmW6C0mkdlOCkCrTXUgitZsShFSZ7kISqd10F5Ok\nRXchidReKkGIiEgsJYg6Lp2ObiJSu6mKqQ7LREc3Eam9VIKow9TRTUQqogRRh6mjm4hURAmiDlNH\nNxGpSFYThJkNNLOFZrbYzK6OWd/ZzKab2Rwze8XMOiSt22pms6Lp6WzGWVepo5uIVCRrCcLM6gMT\ngEHAwcAwMzu4zGa3Ao+4+2HAjcD/Ja372t17RtMp2YqzLlNHNxGpSDbvYuoLLHb3pQBmNhkYDCxI\n2uZg4KfR/MvA1CzGIzHU0U1EypPNKqb2wEdJ75dHy5LNBk6L5ocAzc2sTfS+sZkVmdkbZnZq3AeY\n2ahom6JVq1ZlMnYRkTov343UVwFHm9k7wNHACmBrtK6zuxcCZwN3mNl+ZXd294nuXujuhXvuuWfO\ngq5O1NFNRLIlm1VMK4COSe87RMu2c/ePiUoQZtYMON3d10TrVkSvS83sFaAXsCSL8dY46ugmItmU\nzRLEDKCbmXUxs4bAWUCpu5HMrK2ZJWK4BnggWt7KzBoltgGOpHTbhaCObiKSXVlLEO5eAlwKPAe8\nCzzh7vPN7EYzS9yVNABYaGbvA3sBiRssDwKKzGw2ofH6N+6uBFGGOrqJSDaZu+c7howoLCz0oqKi\nfIeRUwUFoVqprM6dobg419GISE1kZm9H7b07yXcjtaRBHd1EJJuUIGowdXQTkWzScN81nDq6iUi2\nqAQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQSRZ3qeg4hUV+pJ\nnUd6noOIVGcqQeSRnucgItWZEkQe6XkOIlKdKUHkUadOu7ZcRCSXlCDySM9zEJHqTAkij/Q8BxGp\nznQXU57peQ4iUl2pBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiKUGIiEisShOEmf3A\nzJRIRETqmFQu/GcCi8zst2bWPdsBiYhI9VBpgnD3c4BewBLgITP7r5mNMrPmWY9ORETyJqWqI3df\nB/w/YDKwDzAEmGlml2UxNhERyaNU2iBOMbO/Aq8AuwF93X0Q0AP4WXbDExGRfEllsL7Tgdvd/V/J\nC919o5ldmJ2wREQk31JJEOOAlYk3ZrY7sJe7F7v79GwFJiIi+ZVKG8STwLak91ujZQJMmgQFBVCv\nXnidNCnfEYmIZEYqJYgG7r458cbdN5tZwyzGVGNMmgSjRsHGjeH9hx+G96BnPIhIzZdKCWKVmZ2S\neGNmg4HPsxdSzXHttTuSQ8LGjWG5iEhNl0oJYjQwyczuAgz4CDgvq1HVEMuW7dpyEZGapNIE4e5L\ngO+YWbPo/YasR1VDdOoUqpXilouI1HQpdZQzs5OAi4Gfmtn1ZnZ9ivsNNLOFZrbYzK6OWd/ZzKab\n2Rwze8XMOiStG2Fmi6JpRKpfKJfGj4cmTUova9IkLBcRqelS6Sj3R8J4TJcRqpjOADqnsF99YAIw\nCDgYGGZmB5fZ7FbgEXc/DLgR+L9o39bAr4DDgb7Ar8ysVYrfKWeGD4eJE6FzZzALrxMnqoFaRGqH\nVEoQ/dz9POBLd78BOAI4IIX9+gKL3X1pdBfUZGBwmW0OBl6K5l9OWv994AV3/8LdvwReAAam8Jk5\nN3w4FBfDtm3hVclBRGqLVBLEpuh1o5ntC2whjMdUmfaEBu2E5dGyZLOB06L5IUBzM2uT4r5EgwYW\nmVnRqlWrUghJRERSlUqCeMbMWgK3ADOBYuDPGfr8q4Cjzewd4GhgBaEjXkrcfaK7F7p74Z577pmh\nkEREBCq5iyl6UNB0d18DPGVmfwcau/vaFI69AuiY9L5DtGw7d/+YqAQR3SV1uruvMbMVwIAy+76S\nwmeKiEiGVFiCcPdthIbmxPtvUkwOADOAbmbWJep5fRbwdPIGZtY26Wl11wAPRPPPASeYWauocfqE\naJmIiORIKlVM083sdDOzXTmwu5cAlxIu7O8CT7j7fDO7Maln9gBgoZm9D+wFjI/2/QK4iZBkZgA3\nRstERCRHzN0r3sBsPdAUKCE0WBvg7r5H9sNLXWFhoRcVFeU7DBGRGsXM3nb3wrh1qfSk1qNFRUTq\noEoThJkdFbe87AOE6qpvvoHf/Q5KSmD//XdMrapdtz4RkV2TymB9P0+ab0zoAPc28L2sRFSDbN4M\nP/whPP30zuvatCmdMBJTt27QunXoeS0iUp2lUsX0g+T3ZtYRuCNrEdUQW7bAmWeG5HDXXXDBBbB0\nKSxeHKZFi8Lrv/8Nf/4zJDf1tGy5c+L43vegY8fyP09EJNdSKUGUtRw4KNOB1CRbtsBZZ8HUqXDn\nnXDJJWH5IYeEqaxvvoEPPtiRPBLTjBnw5JOwNeoa2L9/OO4ZZ4D6/YlIvqVyF9MfgMRG9YCeQLG7\nn5Pl2HZJru5iKimBs88OF/bbb4crrkjveFu2wPvvw1//Co8/DgsWQP36cNxxMGwYDBkCe1Sr+8VE\npDap6C6mVBJE8lDbJYTk8J8MxpcRuUgQJSVwzjkwZQrceiv87GeZPb47zJ0bEsXkyWHwv0aN4KST\nQrI46STYfffMfNb69TB/PsyZAwsXQp8+MHQoNNTDZEXqlHQTRFNgk7tvjd7XBxq5+8YKd8yxbCeI\nrVvhvPNCe8LNN8PYsVn7KCAkizffDMliyhT49FNo1gxOPTUki+OPh912q/w4JSWhPWTOnJB8EtMH\nH+zYpkGDsF27dvDjH8NFF6k9RKSuSDdBvAEcl3iSXDRm0vPu3i/jkaYhmwli61YYORIeewz+93/h\nmmuy8jEVfv4rr4Rk8dRTsGZNuEtq6NCQLPr3D3dFrVwZLv7JyeDdd0MbCISqqwMOgEMPDdNhh4XX\nTp3gxRdhwgT4+9/DsQYPDm0r3/ue7rgSqc3STRCz3L1nZcvyLVsJYutWuPBCePhhuOkmuO66jH/E\nLtm8GZ57LiSLv/0NNm6EvfcOy79IGoxk3313TgTdu0PjxhUfv7gY7r0X/vQn+PxzOPBAuPhiGDEC\nWrTI6lcTkTxIN0H8B7jM3WdG7/sAd7n7ERmPNA3ZSBDbtsGPfgQPPgg33ADXp/Sg1dz56it45pmQ\nKJo335EMvvWtUMJIx6ZNoSF+woRQ1dW0aWh/ueSS8DkiUjukmyC+TXga3MeEcZj2Bs5097czHWg6\nMp0gtm0LdfF/+lNIDDfckLFD1zhvvx0SxeOPh8TRv39IFEOGqFFbpKZLK0FEB9gNODB6u9Ddt2Qw\nvozIZILYti1Uq9x7L1x7bahaUj08rF4NDz0Ed98dOgXuvfeORu327UPyWLMGvvxyx2vyfHnL1q4N\nx0pUiSWmggKol8p4wyJSZemWIC4BJkUPDSJ6PsMwd78745GmIVMJwj38dXzPPXD11aFRWsmhtG3b\nQjvIhAkwbVo4Pw0bhgRRkSZNQi/yVq12vLZqFfp5LF8eGtWXLt2xfbNmoeNhog0lMaVbfSYiO2Sj\nkfodd++VwRjTlokE4Q6XXx6Gzvj5z8PtrEoOFVu6FB55JDSWl734JyeBFi1Cn47KJPpnJN+SO3du\nKL0k7LNP6YSRSCANqjIugEgdl26CmAsc5tGGUT+IOe4eM6hE/qSbINzhyivh97+Hn/40dIRTcqge\n3OGTT3buy7FgwY5beLt0gauugvPPz1xnwlRs3QovvxzuIuvaNcSRSiIUqS7STRC3AJ2Be6NFFwHL\n3P2qjEaZpnQShHu4uPzud/CTn4QhNJQcqr+Skh1jWt19N7zxRhjD6rLLQjVh69bZ++zPP4cHHoA/\n/rF0p0Oz0B6z335h6tq19LxG8pXqJt0EUQ8YBRwbLZoD7O3ul2Q0yjRVNUG4h17Rt94aLiy//73+\nA9dE7vDaa6FacNq0cFvuj38cSoOZ7BX+1lshGU2eHEovRx8dbmjo2BGWLAnT0qU75j/5pPT+LVrs\nnDT22y/0N2nfXr89yb1M3MXUCzgb+CGwFHjK3e/KaJRpqmqCeO896Nkz9Hf4wx/0H7Q2mDsXfvvb\ncFuuWRhccezY+JF2U/H112G4kwkToKgoNJ6fdx6MGRP6nFTkq69CCaNs4li6NCzfknQ/YIsW4XiH\nHBJeE/Pt2lUtbpFUVClBmNkBwLBo+hyYAlzl7p2zFWg60qlimjcv/EdUcqhdPvwwVBv+6U+hEf3k\nk+EXv4Dvfje1/T/4INzNdv/9oZf6QQeFqqtzz83MCLtbt4a7t5YsCUOizJ8ffovz5oVbgBP23DM+\ncbRsmX4MIlVNENuA14AL3X1xtGypu3fNWqRpyNVw31LzrF4d/vq/884w369fKFH84Ac797PYtg3+\n+c+w/bPPhvWnnhoSw4ABufkjItEoP2/ejqSReN2wYcd27dvvSBpt26b3mY0bhxJMeVNlQ7RIzVXV\nBHEqcBZwJPBPQm/qP7l7l2wFmg4lCKnMxo2hYfm228KYUwcdFG5nHj48XHgfeCCUGJYuhb32glGj\nwtShQ74jD9xh2bLSJY3588PdXJX1QUlXw4alE0bLlqXf7713uIOrSxc1xtc0mRjuezChqul7wCPA\nX939+UwHmg4lCElVSQk88URo0J4zJ1zc1qypucOIbNtWui1jV7mH7752bekp0cs9lWn9+tLHbN58\nR8KIm5o2Te87S+ak3UiddKBWwBmEsZiOrWz7XFKCkF3lHnqE33NP6Hx38cWh053suvXrQ5tN3LR0\naSi9JWvXrnTCaNEi/Hts21b+a0XrTjwxPIVRdl3GEkR1pgQhUj25w6pV5SePZctCqa4iZqE9qOxr\nvXph361b4S9/Ce1KsmsqShAanEBEssoslBjatYPDD995/datoU9JXAIwq7wtY926UHo44wz4xz/g\n2DzXbSSq7DZsKD2tX7/zssTUrBkcfHCYDjig+twUoAQhInlVv34YyLGq9tgj3HE2YACccgq88EK4\nUy0XNm8OnTFfeKH0BX/bttSP0bRp6GuT2KdePdh//x0JIzF1757bYWRACUJEaoE2bcJF+qijQnvE\nSy9B797Z/cy1a+H002H69JCY2rULJYFdmXbfPSSETZvg/ffDHWkLFuy4O+2ZZ0IJC0JJqmvX0knj\nkENC4shWo7/aIESk1li2LNyJtnEjvPpquIhmw/LlIRG9+27oSHneedn5nM2bYdGiHYkjkTzef7/0\nnWvHHhueK18VaoMQkTqhU6fwF33//qFd4rXXwlhXmTR3LgwaFNo+pk2D44/P7PGTNWwYSgllh4nZ\nsiX0wE8kDZUgKqEShIgkzJsXBlJs3hz+/e/MdXZ86aXQR6ZZs5AcevTIzHHzqaIShB7oKCK1zre+\nFfq4fPFFKEl89ln6x5w0CQYODCP3vvFG7UgOlVGCEJFaqbAw3Pa6bBmccELpARB3hTv85jdwzjlw\n5JGhRJLJIeSrMyUIEam1+veHqVNDY/KgQTsPCVKZrVvD0CvXXANnnRUGcqxLo+gqQYhIrXbCCWHs\nraKicDvq11+ntt/GjXDaaWEolrFjQxVTXXucrBKEiNR6gwfDI4+EW19PPz3cPlqRzz6DY44J/RDu\nuisM7Fh2aPi6QLe5ikidcPbZoZfzRReFId4ffxwaxFwBFy8OjdErVoTxnU49NfexVhdKECJSZ4wa\nFZLEz34W+g488EDpksGbb4YnD7qHW1qPOCJ/sVYHWS00mdlAM1toZovN7OqY9Z3M7GUze8fM5pjZ\nidHyAjP72sxmRdMfsxmniNQdP/0pjBsHDz8Ml18ekgHA3/4WqpX22ANef13JAbJYgjCz+sAE4Hhg\nOTDDzJ529wVJm10HPOHu95jZwcA0oCBat8Tde2YrPhGpu66/PpQkbr01dHrr1Akuuwz69IG//z2M\nqyTZrWLqCyx296UAZjaZ8GS65AThQOLx7y2Aj7MYj4gIEAa+++1vQ5K4+eaw7OSTYfJkPe0uWTYT\nRHvgo6T3y4Gyo8GPA543s8uApkDyM6G6mNk7wDrgOnd/rewHmNkoYBRAp06dMhe5iNR6ZjBhQhhq\nvEEDGD8+vtG6Lsv36RgGPOTut5nZEcCjZvYtYCXQyd1Xm1kfYKqZHeLu65J3dveJwEQIYzHlOngR\nqdnq1YPbbst3FNVXNhupVwDJHdI7RMuSXQg8AeDu/wUaA23d/Rt3Xx0tfxtYAhyQxVhFRKSMbCaI\nGUA3M+tiZg2Bs4Cny2yzDDgWwMwOIiSIVWa2Z9TIjZl1BboBS7MYq4iIlJG1KiZ3LzGzS4HngPrA\nA+4+38xuBIrc/WngZ8B9ZnYlocF6pLu7mR0F3GhmW4BtwGh3/yJbsYqIyM70PAgRkTpMz4MQEZFd\npgQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSW\nEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhK\nECIiEksJQkREYjXIdwAiUvNt2bKF5cuXs2nTpnyHIuVo3LgxHTp0YLfddkt5HyUIEUnb8uXLad68\nOQUFBZhZvsORMtyd1atXs3z5crp06ZLyfqpiEpG0bdq0iTZt2ig5VFNmRps2bXa5hKcEISIZoeRQ\nvVXl30cJQkREYilBiEjOTZoEBQVQr154nTQpveOtXr2anj170rNnT/bee2/at2+//f3mzZsr3Leo\nqIjLL7+80s/o169fekHWQGqkFpGcmjQJRo2CjRvD+w8/DO8Bhg+v2jHbtGnDrFmzABg3bhzNmjXj\nqquu2r6+pKSEBg3iL3eFhYUUFhZW+hmvv/561YKrwVSCEJGcuvbaHckhYePGsDyTRo4cyejRozn8\n8MMZO3Ysb731FkcccQS9evWiX79+LFy4EIBXXnmFk08+GQjJ5YILLmDAgAF07dqVO++8c/vxmjVr\ntn37AQMGMHToULp3787w4cNxdwCmTZtG9+7d6dOnD5dffvn24yYrLi6mf//+9O7dm969e5dKPDff\nfDOHHnooPXr04OqrrwZg8eLFHHfccfTo0YPevXuzZMmSzJ6oCqgEISI5tWzZri1Px/Lly3n99dep\nX78+69at47XXXqNBgwa8+OKL/M///A9PPfXUTvu89957vPzyy6xfv54DDzyQMWPG7NR34J133mH+\n/Pnsu+++HHnkkfznP/+hsLCQiy66iH/961906dKFYcOGxcbUrl07XnjhBRo3bsyiRYsYNmwYRUVF\nPPvss/ztb3/jzTffpEmTJgFsXO8AAA7bSURBVHzxxRcADB8+nKuvvpohQ4awadMmtm3blvkTVQ4l\nCBHJqU6dQrVS3PJMO+OMM6hfvz4Aa9euZcSIESxatAgzY8uWLbH7nHTSSTRq1IhGjRrRrl07Pv30\nUzp06FBqm759+25f1rNnT4qLi2nWrBldu3bd3s9g2LBhTJw4cafjb9myhUsvvZRZs2ZRv3593n//\nfQBefPFFzj//fJo0aQJA69atWb9+PStWrGDIkCFA6OyWS6piEpGcGj8eomvgdk2ahOWZ1rRp0+3z\nv/zlLznmmGOYN28ezzzzTLl9Aho1arR9vn79+pSUlFRpm/Lcfvvt7LXXXsyePZuioqJKG9HzSQlC\nRHJq+HCYOBE6dwaz8DpxYtUbqFO1du1a2rdvD8BDDz2U8eMfeOCBLF26lOLiYgCmTJlSbhz77LMP\n9erV49FHH2Xr1q0AHH/88Tz44INsjBpovvjiC5o3b06HDh2YOnUqAN9888329bmgBCEiOTd8OBQX\nw7Zt4TXbyQFg7NixXHPNNfTq1WuX/uJP1e67787dd9/NwIED6dOnD82bN6dFixY7bXfxxRfz8MMP\n06NHD957773tpZyBAwdyyimnUFhYSM+ePbn11lsBePTRR7nzzjs57LDD6NevH5988knGYy+PJVrf\na7rCwkIvKirKdxgiddK7777LQQcdlO8w8m7Dhg00a9YMd+eSSy6hW7duXHnllfkOa7u4fycze9vd\nY+/zVQlCRCRD7rvvPnr27MkhhxzC2rVrueiii/IdUlqymiDMbKCZLTSzxWZ2dcz6Tmb2spm9Y2Zz\nzOzEpHXXRPstNLPvZzNOEZFMuPLKK5k1axYLFixg0qRJ2+9IqqmydpurmdUHJgDHA8uBGWb2tLsv\nSNrsOuAJd7/HzA4GpgEF0fxZwCHAvsCLZnaAu2/NVrwiIlJaNksQfYHF7r7U3TcDk4HBZbZxYI9o\nvgXwcTQ/GJjs7t+4+wfA4uh4IiKSI9lMEO2Bj5LeL4+WJRsHnGNmywmlh8t2YV/MbJSZFZlZ0apV\nqzIVt4iIkP9G6mHAQ+7eATgReNTMUo7J3Se6e6G7F+65555ZC1JEpC7KZoJYAXRMet8hWpbsQuAJ\nAHf/L9AYaJviviIiABxzzDE899xzpZbdcccdjBkzptx9BgwYQOLW+BNPPJE1a9bstM24ceO290co\nz9SpU1mwYEfT6vXXX8+LL764K+FXW9lMEDOAbmbWxcwaEhqdny6zzTLgWAAzO4iQIFZF251lZo3M\nrAvQDXgri7GKSA02bNgwJk+eXGrZ5MmTyx0wr6xp06bRsmXLKn122QRx4403ctxxx1XpWNVN1u5i\ncvcSM7sUeA6oDzzg7vPN7EagyN2fBn4G3GdmVxIarEd66Lk338yeABYAJcAluoNJpGa44gqIHs2Q\nMT17wh13lL9+6NChXHfddWzevJmGDRtSXFzMxx9/TP/+/RkzZgwzZszg66+/ZujQodxwww077V9Q\nUEBRURFt27Zl/PjxPPzww7Rr146OHTvSp08fIPRxmDhxIps3b2b//ffn0UcfZdasWTz99NO8+uqr\n/PrXv+app57ipptu4uSTT2bo0KFMnz6dq666ipKSEr797W9zzz330KhRIwoKChgxYgTPPPMMW7Zs\n4cknn6R79+6lYiouLubcc8/lq6++AuCuu+7a/tCim2++mccee4x69eoxaNAgfvOb37B48WJGjx7N\nqlWrqF+/Pk8++ST77bdfWuc9q20Q7j7N3Q9w9/3cfXy07PooOeDuC9z9SHfv4e493f35pH3HR/sd\n6O7PZjNOEanZWrduTd++fXn22XCpmDx5Mj/84Q8xM8aPH09RURFz5szh1VdfZc6cOeUe5+2332by\n5MnMmjWLadOmMWPGjO3rTjvtNGbMmMHs2bM56KCDuP/+++nXrx+nnHIKt9xyC7NmzSp1Qd60aRMj\nR45kypQpzJ07l5KSEu65557t69u2bcvMmTMZM2ZMbDVWYljwmTNnMmXKlO1PvUseFnz27NmMHTsW\nCMOCX3LJJcyePZvXX3+dffbZJ72Tiob7FpEMq+gv/WxKVDMNHjyYyZMnc//99wPwxBNPMHHiREpK\nSli5ciULFizgsMMOiz3Ga6+9xpAhQ7Z3cDvllFO2r5s3bx7XXXcda9asYcOGDXz/+xX33124cCFd\nunThgAMOAGDEiBFMmDCBK664AggJB6BPnz785S9/2Wn/6jAseL7vYsq7TD8bV0TyY/DgwUyfPp2Z\nM2eyceNG+vTpwwcffMCtt97K9OnTmTNnDieddFK5w3xXZuTIkdx1113MnTuXX/3qV1U+TkJiyPDy\nhguvDsOC1+kEkXg27ocfgvuOZ+MqSYjUPM2aNeOYY47hggsu2N44vW7dOpo2bUqLFi349NNPt1dB\nleeoo45i6tSpfP3116xfv55nnnlm+7r169ezzz77sGXLFiYlXSSaN2/O+vXrdzrWgQceSHFxMYsX\nLwbCqKxHH310yt+nOgwLXqcTRK6ejSsiuTFs2DBmz569PUH06NGDXr160b17d84++2yOPPLICvfv\n3bs3Z555Jj169GDQoEF8+9vf3r7upptu4vDDD+fII48s1aB81llnccstt9CrV69Sz4tu3LgxDz74\nIGeccQaHHnoo9erVY/To0Sl/l+owLHidHu67Xr1QcijLLIxTLyKp0XDfNYOG+94F5T0DNxvPxhUR\nqWnqdILI5bNxRURqmjqdIPL1bFyR2qi2VFfXVlX596nz/SCGD1dCEElX48aNWb16NW3atMHM8h2O\nlOHurF69epf7R9T5BCEi6evQoQPLly9Hw+5XX40bN6ZDhw67tI8ShIikbbfddqNLly75DkMyrE63\nQYiISPmUIEREJJYShIiIxKo1PanNbBXwYb7jqEBb4PN8B1EBxZcexZcexZeedOLr7O6xz2yuNQmi\nujOzovK6s1cHii89ii89ii892YpPVUwiIhJLCUJERGIpQeTOxHwHUAnFlx7Flx7Fl56sxKc2CBER\niaUShIiIxFKCEBGRWEoQGWJmHc3sZTNbYGbzzewnMdsMMLO1ZjYrmq7PQ5zFZjY3+vydHsFnwZ1m\nttjM5phZ7xzGdmDSuZllZuvM7Ioy2+T0HJrZA2b2mZnNS1rW2sxeMLNF0WurcvYdEW2zyMxG5DC+\nW8zsvejf769m1rKcfSv8LWQxvnFmtiLp3/DEcvYdaGYLo9/i1TmMb0pSbMVmNqucfXNx/mKvKzn7\nDbq7pgxMwD5A72i+OfA+cHCZbQYAf89znMVA2wrWnwg8CxjwHeDNPMVZH/iE0Iknb+cQOAroDcxL\nWvZb4Opo/mrg5pj9WgNLo9dW0XyrHMV3AtAgmr85Lr5UfgtZjG8ccFUK//5LgK5AQ2B22f9P2Yqv\nzPrbgOvzeP5iryu5+g2qBJEh7r7S3WdG8+uBd4H2+Y2qSgYDj3jwBtDSzPbJQxzHAkvcPa+94939\nX8AXZRYPBh6O5h8GTo3Z9fvAC+7+hbt/CbwADMxFfO7+vLuXRG/fAHZtjOcMKuf8paIvsNjdl7r7\nZmAy4bxnVEXxWXiwxQ+BxzP9uamq4LqSk9+gEkQWmFkB0At4M2b1EWY228yeNbNDchpY4MDzZva2\nmY2KWd8e+Cjp/XLyk+jOovz/mPk+h3u5+8po/hNgr5htqst5vIBQIoxT2W8hmy6NqsAeKKd6pDqc\nv/7Ap+6+qJz1OT1/Za4rOfkNKkFkmJk1A54CrnD3dWVWzyRUmfQA/gBMzXV8wHfdvTcwCLjEzI7K\nQwwVMrOGwCnAkzGrq8M53M5DWb5a3ituZtcCJcCkcjbJ12/hHmA/oCewklCNUx0No+LSQ87OX0XX\nlWz+BpUgMsjMdiP8I05y97+UXe/u69x9QzQ/DdjNzNrmMkZ3XxG9fgb8lVCUT7YC6Jj0vkO0LJcG\nATPd/dOyK6rDOQQ+TVS7Ra+fxWyT1/NoZiOBk4Hh0QVkJyn8FrLC3T91963uvg24r5zPzff5awCc\nBkwpb5tcnb9yris5+Q0qQWRIVF95P/Cuu/+unG32jrbDzPoSzv/qHMbY1MyaJ+YJjZnzymz2NHBe\ndDfTd4C1SUXZXCn3L7d8n8PI00DijpARwN9itnkOOMHMWkVVKCdEy7LOzAYCY4FT3H1jOduk8lvI\nVnzJbVpDyvncGUA3M+sSlSjPIpz3XDkOeM/dl8etzNX5q+C6kpvfYDZb4OvSBHyXUMybA8yKphOB\n0cDoaJtLgfmEOzLeAPrlOMau0WfPjuK4NlqeHKMBEwh3kMwFCnMcY1PCBb9F0rK8nUNColoJbCHU\n4V4ItAGmA4uAF4HW0baFwJ+S9r0AWBxN5+cwvsWEuufE7/CP0bb7AtMq+i3kKL5Ho9/WHMKFbp+y\n8UXvTyTctbMkl/FFyx9K/OaSts3H+SvvupKT36CG2hARkViqYhIRkVhKECIiEksJQkREYilBiIhI\nLCUIERGJpQQhUgkz22qlR5nN2MiiZlaQPJKoSHXSIN8BiNQAX7t7z3wHIZJrKkGIVFH0PIDfRs8E\neMvM9o+WF5jZS9FgdNPNrFO0fC8Lz2eYHU39okPVN7P7ovH+nzez3aPtL4+eAzDHzCbn6WtKHaYE\nIVK53ctUMZ2ZtG6tux8K3AXcES37A/Cwux9GGCjvzmj5ncCrHgYa7E3ogQvQDZjg7ocAa4DTo+VX\nA72i44zO1pcTKY96UotUwsw2uHuzmOXFwPfcfWk0oNon7t7GzD4nDB+xJVq+0t3bmtkqoIO7f5N0\njALCmP3dove/AHZz91+b2T+BDYQRa6d6NEihSK6oBCGSHi9nfld8kzS/lR1tgycRxsXqDcyIRhgV\nyRklCJH0nJn0+t9o/nXC6KMAw4HXovnpwBgAM6tvZi3KO6iZ1QM6uvvLwC+AFsBOpRiRbNJfJCKV\n291KP7j+n+6euNW1lZnNIZQChkXLLgMeNLOfA6uA86PlPwEmmtmFhJLCGMJIonHqA49FScSAO919\nTca+kUgK1AYhUkVRG0Shu3+e71hEskFVTCIiEkslCBERiaUShIiIxFKCEBGRWEoQIiISSwlCRERi\nKUGIiEis/w/1hX1zIYgruQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQgFbJn5bnuk",
        "colab_type": "text"
      },
      "source": [
        "점선은 훈련 손실과 정확도이고 실선은 검증 손실과 정확도입니다. 신경망의 무작위한 초기화 때문에 사람마다 결과거 조금 다를 수 있습니다.\n",
        "\n",
        "여기에서 볼 수 있듯이 훈련 손실이 에포크마다 감소하고 훈련 정확도는 에포크마다 증가합니다. 경사 하강법 최적화를 사용했을 때 반복마다 최소화되는 것이 손실이므로 기대했던 대로입니다. 검증 손실과 정확도는 이와 같지 않습니다. 4번째 에포크에서 그래프가 역전되는 것 같습니다. 이것이 훈련 세트에서 잘 작동하는 모델이 처음 보는 데이터에 잘 작동하지 않을 수 있다고 앞서 언급한 경고의 한 사례입니다. 정확한 용어로 말하면 과대적합되었다고 합니다. 2번째 에포크 이후부터 훈련 데이터에 과도하게 최적화되어 훈련 데이터에 특화된 표현을 학습하므로 훈련 세트 이외의 데이터에는 일반화되지 못합니다.\n",
        "\n",
        "이런 경우에 과대적합을 방지하기 위해서 3번째 에포크 이후에 훈련을 중지할 수 있습니다. 일반적으로 4장에서 보게 될 과대적합을 완화하는 다양한 종류의 기술을 사용할 수 있습니다.\n",
        "\n",
        "처음부터 다시 새로운 신경망을 4번의 에포크 동안만 훈련하고 테스트 데이터에서 평가해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f31gd3MMbnul",
        "colab_type": "code",
        "outputId": "554f6e3f-7a5d-4a85-f57f-c3ed4928222a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "25000/25000 [==============================] - 2s 78us/step - loss: 0.4420 - acc: 0.8242\n",
            "Epoch 2/4\n",
            "25000/25000 [==============================] - 2s 64us/step - loss: 0.2550 - acc: 0.9100\n",
            "Epoch 3/4\n",
            "25000/25000 [==============================] - 2s 63us/step - loss: 0.1950 - acc: 0.9306\n",
            "Epoch 4/4\n",
            "25000/25000 [==============================] - 2s 64us/step - loss: 0.1643 - acc: 0.9423\n",
            "25000/25000 [==============================] - 2s 67us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z8p7iShbnuo",
        "colab_type": "code",
        "outputId": "ffe8b8d8-d604-4694-d161-b2b8db579a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3026695297241211, 0.88128]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpA0ZcWlbnut",
        "colab_type": "text"
      },
      "source": [
        "아주 단순한 방식으로도 87%의 정확도를 달성했습니다. 최고 수준의 기법을 사용하면 95%에 가까운 성능을 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqDbqCVGbnuu",
        "colab_type": "text"
      },
      "source": [
        "## 훈련된 모델로 새로운 데이터에 대해 예측하기\n",
        "\n",
        "모델을 훈련시킨 후에 이를 실전 환경에서 사용하고 싶을 것입니다. `predict` 메서드를 사용해서 어떤 리뷰가 긍정일 확률을 예측할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg1M_itPbnuv",
        "colab_type": "code",
        "outputId": "c71c8f13-f8c0-405d-ee59-1ddbe1bfd984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "model.predict(x_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24029016],\n",
              "       [0.99994195],\n",
              "       [0.9366751 ],\n",
              "       ...,\n",
              "       [0.13495767],\n",
              "       [0.12189206],\n",
              "       [0.7899916 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qKfqWtFkJbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "ae8a7b6d-8d51-4de6-8abc-14d62cb14e24"
      },
      "source": [
        "x_test"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 1., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ECF50OclQpd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "270e80a1-5855-47dd-ee79-4e7953a03ad0"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ityjddN_bnuz",
        "colab_type": "text"
      },
      "source": [
        "여기에서처럼 이 모델은 어떤 샘플에 대해 확신을 가지고 있지만(0.99 또는 그 이상, 0.01 또는 그 이하) 어떤 샘플에 대해서는 확신이 부족합니다(0.6, 0.4). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGKHm93dbnu0",
        "colab_type": "text"
      },
      "source": [
        "## 추가 실험\n",
        "\n",
        "* 여기에서는 두 개의 은닉층을 사용했습니다. 한 개 또는 세 개의 은닉층을 사용하고 검증과 테스트 정확도에 어떤 영향을 미치는지 확인해 보세요.\n",
        "* 층의 은닉 유닛을 추가하거나 줄여 보세요: 32개 유닛, 64개 유닛 등\n",
        "* `binary_crossentropy` 대신에 `mse` 손실 함수를 사용해 보세요.\n",
        "* `relu` 대신에 `tanh` 활성화 함수(초창기 신경망에서 인기 있었던 함수입니다)를 사용해 보세요.\n",
        "\n",
        "다음 실험을 진행하면 여기에서 선택한 구조가 향상의 여지는 있지만 어느 정도 납득할 만한 수준이라는 것을 알게 것입니다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zwMGfv1bnu2",
        "colab_type": "text"
      },
      "source": [
        "## 정리\n",
        "\n",
        "다음은 이 예제에서 배운 것들입니다:\n",
        "\n",
        "* 원본 데이터를 신경망에 텐서로 주입하기 위해서는 꽤 많은 전처리가 필요합니다. 단어 시퀀스는 이진 벡터로 인코딩될 수 있고 다른 인코딩 방식도 있습니다.\n",
        "* `relu` 활성화 함수와 함께 `Dense` 층을 쌓은 네트워크는 (감성 분류를 포함하여) 여러 종류의 문제에 적용할 수 있어서 앞으로 자주 사용하게 될 것입니다.\n",
        "* (출력 클래스가 두 개인) 이진 분류 문제에서 네트워크는 하나의 유닛과 `sigmoid` 활성화 함수를 가진 `Dense` 층으로 끝나야 합니다. 이 신경망의 출력은 확률을 나타내는 0과 1 사이의 스칼라 값입니다.\n",
        "* 이진 분류 문제에서 이런 스칼라 시그모이드 출력에 대해 사용할 손실 함수는 `binary_crossentropy`입니다.\n",
        "* `rmsprop` 옵티마이저는 문제에 상관없이 일반적으로 충분히 좋은 선택입니다. 걱정할 거리가 하나 줄은 셈입니다.\n",
        "* 훈련 데이터에 대해 성능이 향상됨에 따라 신경망은 과대적합되기 시작하고 이전에 본적 없는 데이터에서는 결과가 점점 나빠지게 됩니다. 항상 훈련 세트 이외의 데이터에서 성능을 모니터링해야 합니다."
      ]
    }
  ]
}